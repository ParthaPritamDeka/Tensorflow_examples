{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SAMPLE CLASSIFICATION USING DNN USING TENSORFLOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used California Census Data, it has various features of an individual to predict what class of income they belong to in (>50k or <=50k). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in the census_data.csv data with pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv(\"census_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country  income_bracket  \n",
       "0             0              40   United-States               0  \n",
       "1             0              13   United-States               0  \n",
       "2             0              40   United-States               0  \n",
       "3             0              40   United-States               0  \n",
       "4             0              40            Cuba               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(census[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32561\n"
     ]
    }
   ],
   "source": [
    "print (len(census))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "** Convert the Label column to 0s and 1s instead of strings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['income_bracket'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fix(label):\n",
    "    if label==' <=50K':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "census['income_bracket'] = census['income_bracket'].apply(label_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cool Alternative\n",
    "# lambda label:int(label==' <=50k')\n",
    "\n",
    "# census['income_bracket'].apply(lambda label: int(label==' <=50K'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Train Test Split on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = census.drop('income_bracket',axis=1)\n",
    "y_labels = census['income_bracket']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data,y_labels,stratify=y_labels,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Feature Columns for tf.esitmator\n",
    "\n",
    "** Take note of categorical vs continuous values! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'education', 'education_num', 'marital_status',\n",
       "       'occupation', 'relationship', 'race', 'gender', 'capital_gain',\n",
       "       'capital_loss', 'hours_per_week', 'native_country', 'income_bracket'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import Tensorflow **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pdeka\\AppData\\Local\\Continuum\\anaconda3_new\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Create the tf.feature_columns for the categorical values. Use vocabulary lists or just use hash buckets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = tf.feature_column.categorical_column_with_vocabulary_list(\"gender\", [\"Female\", \"Male\"])\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket(\"occupation\", hash_bucket_size=1000)\n",
    "marital_status = tf.feature_column.categorical_column_with_hash_bucket(\"marital_status\", hash_bucket_size=1000)\n",
    "relationship = tf.feature_column.categorical_column_with_hash_bucket(\"relationship\", hash_bucket_size=1000)\n",
    "education = tf.feature_column.categorical_column_with_hash_bucket(\"education\", hash_bucket_size=1000)\n",
    "workclass = tf.feature_column.categorical_column_with_hash_bucket(\"workclass\", hash_bucket_size=1000)\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket(\"native_country\", hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding on the categorical columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "print (len(census['native_country'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = tf.feature_column.embedding_column(gender, 2)\n",
    "occupation = tf.feature_column.embedding_column(occupation, 15)\n",
    "marital_status = tf.feature_column.embedding_column(marital_status, 7)\n",
    "relationship = tf.feature_column.embedding_column(relationship, 6)\n",
    "education = tf.feature_column.embedding_column(education, 16)\n",
    "workclass = tf.feature_column.embedding_column(workclass, 9)\n",
    "native_country = tf.feature_column.embedding_column(native_country, 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the continuous feature_columns for the continuous values using numeric_column **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column(\"age\")\n",
    "education_num = tf.feature_column.numeric_column(\"education_num\")\n",
    "capital_gain = tf.feature_column.numeric_column(\"capital_gain\")\n",
    "capital_loss = tf.feature_column.numeric_column(\"capital_loss\")\n",
    "hours_per_week = tf.feature_column.numeric_column(\"hours_per_week\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Put all these variables into a single list with the variable name feat_cols **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [gender,occupation,marital_status,relationship,education,workclass,native_country,\n",
    "            age,education_num,capital_gain,capital_loss,hours_per_week]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Input Function\n",
    "\n",
    "** Batch_size is up to you. But do make sure to shuffle!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func=tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=100,num_epochs=None,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your model with tf.estimator\n",
    "\n",
    "**For DNNClassifier, keep in mind you'll need to create embedded columns out of the cateogrical feature that use strings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\pdeka\\AppData\\Local\\Temp\\tmpqccs809_\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\pdeka\\\\AppData\\\\Local\\\\Temp\\\\tmpqccs809_', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000020CB0A48320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNClassifier(hidden_units=[2048, 1024, 512, 256],feature_columns=feat_cols,n_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train your model on the data, for at least 5000 steps or epochs. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\pdeka\\AppData\\Local\\Temp\\tmpqccs809_\\model.ckpt.\n",
      "INFO:tensorflow:loss = 221.7929, step = 1\n",
      "INFO:tensorflow:global_step/sec: 19.8524\n",
      "INFO:tensorflow:loss = 82.852745, step = 101 (5.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0671\n",
      "INFO:tensorflow:loss = 50.55077, step = 201 (4.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4526\n",
      "INFO:tensorflow:loss = 42.789577, step = 301 (5.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.6787\n",
      "INFO:tensorflow:loss = 34.70185, step = 401 (4.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1069\n",
      "INFO:tensorflow:loss = 32.66651, step = 501 (5.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.8177\n",
      "INFO:tensorflow:loss = 34.20966, step = 601 (5.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.4037\n",
      "INFO:tensorflow:loss = 32.302696, step = 701 (4.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.9607\n",
      "INFO:tensorflow:loss = 35.70592, step = 801 (5.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2138\n",
      "INFO:tensorflow:loss = 31.261171, step = 901 (6.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1124\n",
      "INFO:tensorflow:loss = 39.790997, step = 1001 (5.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2196\n",
      "INFO:tensorflow:loss = 36.4004, step = 1101 (6.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.968\n",
      "INFO:tensorflow:loss = 33.338913, step = 1201 (5.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2621\n",
      "INFO:tensorflow:loss = 35.733067, step = 1301 (4.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.5977\n",
      "INFO:tensorflow:loss = 27.732029, step = 1401 (4.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8169\n",
      "INFO:tensorflow:loss = 32.291294, step = 1501 (4.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.551\n",
      "INFO:tensorflow:loss = 29.89736, step = 1601 (4.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.8711\n",
      "INFO:tensorflow:loss = 40.8846, step = 1701 (5.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2629\n",
      "INFO:tensorflow:loss = 35.401943, step = 1801 (4.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.9388\n",
      "INFO:tensorflow:loss = 41.204945, step = 1901 (5.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2663\n",
      "INFO:tensorflow:loss = 34.060516, step = 2001 (5.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3208\n",
      "INFO:tensorflow:loss = 29.61189, step = 2101 (5.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.0953\n",
      "INFO:tensorflow:loss = 35.176285, step = 2201 (4.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.5622\n",
      "INFO:tensorflow:loss = 45.027462, step = 2301 (4.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.652\n",
      "INFO:tensorflow:loss = 37.107117, step = 2401 (5.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0068\n",
      "INFO:tensorflow:loss = 38.68565, step = 2501 (5.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1971\n",
      "INFO:tensorflow:loss = 36.197765, step = 2601 (4.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7894\n",
      "INFO:tensorflow:loss = 30.021605, step = 2701 (5.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.4625\n",
      "INFO:tensorflow:loss = 37.63475, step = 2801 (4.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.1833\n",
      "INFO:tensorflow:loss = 33.701252, step = 2901 (5.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.1833\n",
      "INFO:tensorflow:loss = 29.31802, step = 3001 (5.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1301\n",
      "INFO:tensorflow:loss = 29.982592, step = 3101 (5.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4903\n",
      "INFO:tensorflow:loss = 44.968063, step = 3201 (5.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8734\n",
      "INFO:tensorflow:loss = 35.12135, step = 3301 (6.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6842\n",
      "INFO:tensorflow:loss = 36.00331, step = 3401 (6.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1828\n",
      "INFO:tensorflow:loss = 36.92864, step = 3501 (6.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.293\n",
      "INFO:tensorflow:loss = 25.995165, step = 3601 (7.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.2444\n",
      "INFO:tensorflow:loss = 37.288063, step = 3701 (5.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.1204\n",
      "INFO:tensorflow:loss = 37.380177, step = 3801 (5.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.986\n",
      "INFO:tensorflow:loss = 32.18924, step = 3901 (4.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.6254\n",
      "INFO:tensorflow:loss = 35.584316, step = 4001 (5.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2756\n",
      "INFO:tensorflow:loss = 34.22191, step = 4101 (4.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7262\n",
      "INFO:tensorflow:loss = 36.069164, step = 4201 (5.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.0396\n",
      "INFO:tensorflow:loss = 35.195858, step = 4301 (4.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.18\n",
      "INFO:tensorflow:loss = 35.182655, step = 4401 (5.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4855\n",
      "INFO:tensorflow:loss = 41.43117, step = 4501 (4.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.467\n",
      "INFO:tensorflow:loss = 28.84233, step = 4601 (4.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2509\n",
      "INFO:tensorflow:loss = 36.026062, step = 4701 (4.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.4\n",
      "INFO:tensorflow:loss = 24.927408, step = 4801 (4.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3626\n",
      "INFO:tensorflow:loss = 34.779064, step = 4901 (4.910 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\pdeka\\AppData\\Local\\Temp\\tmpqccs809_\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 41.06298.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x20cb0a48278>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "** Create a prediction input function. Only supprt X_test data and keep shuffle=False. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fn = tf.estimator.inputs.pandas_input_fn(x=X_test,batch_size=len(X_test),shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use model.predict() and pass in your input function. This will produce a generator of predictions, which you can then transform into a list, with list() **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\pdeka\\AppData\\Local\\Temp\\tmpqccs809_\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = list(model.predict(input_fn=pred_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Each item in your list will look like this: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_ids': array([1], dtype=int64),\n",
       " 'classes': array([b'1'], dtype=object),\n",
       " 'logistic': array([0.81598806], dtype=float32),\n",
       " 'logits': array([1.4893993], dtype=float32),\n",
       " 'probabilities': array([0.1840119 , 0.81598806], dtype=float32)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a list of only the class_ids key values from the prediction list of dictionaries, these are the predictions you will use to compare against the real y_test values. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 1, 1, 0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import classification_report from sklearn.metrics and then see if you can figure out how to use it to easily get a full report of your model's performance on the test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.87      0.88      7417\n",
      "          1       0.63      0.70      0.66      2352\n",
      "\n",
      "avg / total       0.84      0.83      0.83      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,final_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=X_test,\n",
    "      y=y_test,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-24-22:29:27\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\pdeka\\AppData\\Local\\Temp\\tmpqccs809_\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-24-22:29:35\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.8272085, accuracy_baseline = 0.7592384, auc = 0.8803526, auc_precision_recall = 0.65697706, average_loss = 0.3599385, global_step = 5000, label/mean = 0.2407616, loss = 3.5990167, precision = 0.6255673, prediction/mean = 0.2612929, recall = 0.7032313\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(eval_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8272085,\n",
       " 'accuracy_baseline': 0.7592384,\n",
       " 'auc': 0.8803526,\n",
       " 'auc_precision_recall': 0.65697706,\n",
       " 'average_loss': 0.3599385,\n",
       " 'global_step': 5000,\n",
       " 'label/mean': 0.2407616,\n",
       " 'loss': 3.5990167,\n",
       " 'precision': 0.6255673,\n",
       " 'prediction/mean': 0.2612929,\n",
       " 'recall': 0.7032313}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
